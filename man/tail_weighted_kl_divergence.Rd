% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compareDistributions.R
\name{tail_weighted_kl_divergence}
\alias{tail_weighted_kl_divergence}
\title{Calculate tail-weighted KL divergence for discrete distributions}
\usage{
tail_weighted_kl_divergence(
  P,
  Q,
  index = 1:min(c(length(Q), length(P))),
  index.spacing = "equal",
  parameter = list(lambda = 0.2, x0 = 30),
  inverse = FALSE,
  method = "step",
  alignPQ = TRUE
)
}
\arguments{
\item{P}{probability vector 2}

\item{Q}{probability vector 1}

\item{index}{a positive numeric vector containing probability spacing e.g., depth}

\item{index.spacing}{whether index intervals are equally distant i.e., c(1,2,3,4....n), if "equal" than index is c(1,n)}

\item{parameter}{list with lambda -> shape parameter (0 = constant weighting) & x0 -> curve offset (= inflexion point )}

\item{inverse}{changes from right tail to left tail if TRUE}

\item{method}{weighting function along index. Available options are: c("constant", "asymptotic", "linear, "exponential", "sigmoid", "gompertz","step")}

\item{alignPQ}{if TRUE, index end values will be cut off in case of unequal length of P & Q so that length of P & Q is equal}
}
\value{
KL divergence, not symmetrical - changing the input order will change the result
}
\description{
Calculate tail-weighted KL divergence for discrete distributions
}
